{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from data.dataset import PolygonDataset\n",
    "from train.trainer import Trainer\n",
    "from model.nn import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cfg/finetune_osm.yaml', 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "        cls = [k for k, _ in cfg['cls'].items()]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OSM dataset - unnormalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2496/2496 [00:05<00:00, 459.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nuft_spec: 88.02\n",
      "cnn: 42.23\n",
      "deepset: 22.00\n",
      "gcn: 22.12\n",
      "transformer: 35.62\n",
      "dsc_nmp: 31.81\n",
      "polymp: 50.64\n",
      "dsc_polymp: 44.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2504/2504 [00:04<00:00, 531.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nuft_spec: 61.38\n",
      "cnn: 42.09\n",
      "deepset: 21.65\n",
      "gcn: 22.32\n",
      "transformer: 35.30\n",
      "dsc_nmp: 33.23\n",
      "polymp: 39.86\n",
      "dsc_polymp: 36.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:09<00:00, 535.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nuft_spec: 74.42\n",
      "cnn: 42.16\n",
      "deepset: 21.84\n",
      "gcn: 22.22\n",
      "transformer: 35.46\n",
      "dsc_nmp: 32.52\n",
      "polymp: 46.20\n",
      "dsc_polymp: 40.68\n"
     ]
    }
   ],
   "source": [
    "cfg['normalised'] = False\n",
    "\n",
    "for tr in ['o', 'r', None]:\n",
    "    test_df = pd.read_pickle(cfg['osm_test'])\n",
    "    if tr == None:\n",
    "        test_df = test_df[(test_df.name.isin(cls))].reset_index(drop=True)\n",
    "    else:                            \n",
    "        test_df = test_df[(test_df.name.isin(cls)) & (test_df.trans==tr)].reset_index(drop=True)\n",
    "        \n",
    "    test_set = PolygonDataset(test_df, cfg['cls'], transform=None)\n",
    "    test_loader = DataLoader(test_set, \n",
    "                             batch_size=cfg['batch'], \n",
    "                             num_workers=cfg['worker'])\n",
    "    print('*' * 80)\n",
    "    \n",
    "    cfg['nn'] = 'nuft_spec_mlp'\n",
    "    cfg['path'] = f\"save/finetune/unnormalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    nuft_spec_cm, nuft_spec = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'nuft_spec: {nuft_spec_cm.acc()}')\n",
    "    \n",
    "    cfg['nn'] = 'cnn'\n",
    "    cfg['path'] = f\"save/finetune/unnormalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    cnn_cm, cnn = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'cnn: {cnn_cm.acc()}')\n",
    "    \n",
    "    cfg['nn'] = 'deepset'\n",
    "    cfg['path'] = f\"save/finetune/unnormalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    deepset_cm, deepset = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'deepset: {deepset_cm.acc()}')\n",
    "\n",
    "    cfg['nn'] = 'gcn'\n",
    "    cfg['path'] = f\"save/finetune/unnormalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    gcn_cm, gcn = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'gcn: {gcn_cm.acc()}')\n",
    "    \n",
    "    cfg['nn'] = 'transformer'\n",
    "    cfg['path'] = f\"save/finetune/unnormalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    transformer_cm, transformer = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'transformer: {transformer_cm.acc()}')\n",
    "    \n",
    "    cfg['nn'] = 'dsc_nmp'\n",
    "    cfg['path'] = f\"save/finetune/unnormalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    dsc_nmp_cm, dsc_nmp = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'dsc_nmp: {dsc_nmp_cm.acc()}')\n",
    "    \n",
    "    cfg['nn'] = 'polymp'\n",
    "    cfg['path'] = f\"save/finetune/unnormalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    polymp_cm, polymp = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'polymp: {polymp_cm.acc()}')\n",
    "    \n",
    "    cfg['nn'] = 'dsc_polymp'\n",
    "    cfg['path'] = f\"save/finetune/unnormalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    dsc_polymp_cm, dsc_polymp = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'dsc_polymp: {dsc_polymp_cm.acc()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OSM Dataset -- Normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2496/2496 [00:04<00:00, 563.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nuft_spec_mlp: 88.02\n",
      "cnn: 86.30\n",
      "deepset: 94.79\n",
      "gcn: 95.23\n",
      "transformer: 89.10\n",
      "dsc_nmp: 87.58\n",
      "polymp: 96.59\n",
      "dsc_polymp: 95.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2504/2504 [00:03<00:00, 769.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nuft_spec_mlp: 60.66\n",
      "cnn: 72.44\n",
      "deepset: 82.31\n",
      "gcn: 78.15\n",
      "transformer: 68.73\n",
      "dsc_nmp: 66.73\n",
      "polymp: 81.03\n",
      "dsc_polymp: 78.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:14<00:00, 349.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nuft_spec_mlp: 74.26\n",
      "cnn: 79.36\n",
      "deepset: 88.62\n",
      "gcn: 86.94\n",
      "transformer: 78.90\n",
      "dsc_nmp: 77.14\n",
      "polymp: 88.58\n",
      "dsc_polymp: 87.20\n"
     ]
    }
   ],
   "source": [
    "cfg['normalised'] = True\n",
    "\n",
    "for tr in ['o', 'r', None]:\n",
    "    test_df = pd.read_pickle(cfg['osm_test'])\n",
    "    if tr == None:\n",
    "        test_df = test_df[(test_df.name.isin(cls))].reset_index(drop=True)\n",
    "    else:                            \n",
    "        test_df = test_df[(test_df.name.isin(cls)) & (test_df.trans==tr)].reset_index(drop=True)\n",
    "        \n",
    "    test_set = PolygonDataset(test_df, cfg['cls'])\n",
    "    test_loader = DataLoader(test_set, \n",
    "                             batch_size=cfg['batch'], \n",
    "                             num_workers=cfg['worker'])\n",
    "    print('*' * 80)\n",
    "    \n",
    "    cfg['nn'] = 'nuft_spec_mlp'\n",
    "    cfg['path'] = f\"save/finetune/normalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    nuft_spec_cm, nuft_spec_mlp = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'nuft_spec_mlp: {nuft_spec_cm.acc()}')\n",
    "    \n",
    "    cfg['nn'] = 'cnn'\n",
    "    cfg['path'] = f\"save/finetune/normalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    cnn_cm, cnn = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'cnn: {cnn_cm.acc()}')\n",
    "    \n",
    "    cfg['nn'] = 'deepset'\n",
    "    cfg['path'] = f\"save/finetune/normalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    deepset_cm, deepset = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'deepset: {deepset_cm.acc()}')\n",
    "\n",
    "    cfg['nn'] = 'gcn'\n",
    "    cfg['path'] = f\"save/finetune/normalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    gcn_cm, gcn = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'gcn: {gcn_cm.acc()}')\n",
    "    \n",
    "    cfg['nn'] = 'transformer'\n",
    "    cfg['path'] = f\"save/finetune/normalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    transformer_cm, transformer = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'transformer: {transformer_cm.acc()}')\n",
    "    \n",
    "    cfg['nn'] = 'dsc_nmp'\n",
    "    cfg['path'] = f\"save/finetune/normalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    dsc_nmp_cm, dsc_nmp = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'dsc_nmp: {dsc_nmp_cm.acc()}')\n",
    "    \n",
    "    cfg['nn'] = 'polymp'\n",
    "    cfg['path'] = f\"save/finetune/normalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    polymp_cm, polymp = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'polymp: {polymp_cm.acc()}')\n",
    "    \n",
    "    cfg['nn'] = 'dsc_polymp'\n",
    "    cfg['path'] = f\"save/finetune/normalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    dsc_polymp_cm, dsc_polymp = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'dsc_polymp: {dsc_polymp_cm.acc()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OSM Dataset -- Simplified Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shapely.wkt\n",
    "\n",
    "from typing import List\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "from shapely.geometry.base import BaseGeometry\n",
    "\n",
    "\n",
    "def _contour(coords: np.ndarray, \n",
    "             contours: List[int]):\n",
    "    node_idx = np.arange(0, coords.shape[1], dtype=np.int64)\n",
    "    src_list, tgt_list = [], []\n",
    "    \n",
    "    start = 0\n",
    "    for idx, _ in enumerate(contours):\n",
    "        end = sum(contours[:idx+1])\n",
    "        \n",
    "        ids = node_idx[start:end]\n",
    "        src = np.concatenate([ids, ids], axis=0)  \n",
    "        tgt = np.concatenate([np.roll(ids, shift=-1, axis=0), \n",
    "                              np.roll(ids, shift=1, axis=0)], axis=0)\n",
    "        src_list.append(src)\n",
    "        tgt_list.append(tgt)\n",
    "        start = end\n",
    "        \n",
    "    src = np.concatenate(src_list)\n",
    "    tgt = np.concatenate(tgt_list)\n",
    "    edge_index = np.concatenate([src.reshape(1, -1), tgt.reshape(1, -1)], axis=0)\n",
    "    return edge_index \n",
    "\n",
    "\n",
    "def to_edge_index(geom: BaseGeometry):\n",
    "    contours = []   \n",
    "    if isinstance(geom, Polygon):\n",
    "        exter = np.asarray(geom.exterior.coords.xy)[:,0:-1] # drop_last\n",
    "        contours.append(exter.shape[-1])\n",
    "        \n",
    "        inters = []\n",
    "        for i in list(geom.interiors):\n",
    "            inters.append(np.asarray(i.coords.xy)[:,0:-1]) # drop_last\n",
    "            contours.append(inters[-1].shape[-1])\n",
    "            \n",
    "        coords = np.concatenate((exter, *inters), axis=-1) # feat_dim, num_point\n",
    "    elif isinstance(geom, MultiPolygon):\n",
    "        coords = []    \n",
    "        for poly in geom.geoms:\n",
    "            exter = np.asarray(poly.exterior.coords.xy)[:,0:-1] # drop_last\n",
    "            contours.append(exter.shape[-1])\n",
    "            \n",
    "            inters = []\n",
    "            for i in list(poly.interiors):\n",
    "                inters.append(np.asarray(i.coords.xy)[:,0:-1]) # drop_last\n",
    "                contours.append(inters[-1].shape[-1])\n",
    "                        \n",
    "            coords.append(np.concatenate((exter, *inters), axis=-1)) # feat_dim, num_point\n",
    "        coords = np.concatenate(coords, axis=-1) \n",
    "    else:\n",
    "        raise Exception('Wrong geom type.')\n",
    "    \n",
    "    contour = _contour(coords, contours)\n",
    "    return coords, contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2496/2496 [00:05<00:00, 493.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nuft_spec_mlp: 63.50\n",
      "cnn: 93.07\n",
      "deepset: 97.48\n",
      "gcn: 97.72\n",
      "transformer: 92.99\n",
      "dsc_nmp: 91.67\n",
      "polymp: 98.64\n",
      "dsc_polymp: 97.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2504/2504 [00:05<00:00, 494.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nuft_spec_mlp: 15.58\n",
      "cnn: 76.72\n",
      "deepset: 86.22\n",
      "gcn: 82.99\n",
      "transformer: 72.00\n",
      "dsc_nmp: 73.76\n",
      "polymp: 85.06\n",
      "dsc_polymp: 84.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:06<00:00, 749.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nuft_spec_mlp: 39.48\n",
      "cnn: 84.88\n",
      "deepset: 92.06\n",
      "gcn: 90.78\n",
      "transformer: 82.48\n",
      "dsc_nmp: 82.70\n",
      "polymp: 91.44\n",
      "dsc_polymp: 90.74\n"
     ]
    }
   ],
   "source": [
    "tolerant = 1.0\n",
    "\n",
    "for tr in ['o', 'r', None]:\n",
    "    test_df = pd.read_pickle(cfg['osm_test'])\n",
    "    if tr == None:\n",
    "        test_df = test_df[(test_df.name.isin(cls))].reset_index(drop=True)\n",
    "    else:                            \n",
    "        test_df = test_df[(test_df.name.isin(cls)) & (test_df.trans==tr)].reset_index(drop=True)\n",
    "    \n",
    "    for idx, row in test_df.iterrows():\n",
    "        geom = shapely.wkt.loads(row['geom'])\n",
    "        geom = geom.simplify(tolerant)\n",
    "        test_df.iloc[idx]['pos'], \\\n",
    "        test_df.iloc[idx]['contour'] = to_edge_index(geom)\n",
    "        \n",
    "    test_set_sim = PolygonDataset(test_df, cfg['cls'])\n",
    "    test_loader = DataLoader(test_set_sim, \n",
    "                             batch_size=cfg['batch'], \n",
    "                             num_workers=cfg['worker'])\n",
    "    print('*' * 80)\n",
    "    \n",
    "    cfg['nn'] = 'nuft_spec_mlp'\n",
    "    cfg['path'] = f\"save/frac{cfg['frac']}/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    nuft_spec_cm, nuft_spec_mlp = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'nuft_spec_mlp: {nuft_spec_cm.acc()}')\n",
    "    \n",
    "    cfg['nn'] = 'cnn'\n",
    "    cfg['path'] = f\"save/finetune/normalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    cnn_cm, cnn = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'cnn: {cnn_cm.acc()}')\n",
    "    \n",
    "    cfg['nn'] = 'deepset'\n",
    "    cfg['path'] = f\"save/finetune/normalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    deepset_cm, deepset = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'deepset: {deepset_cm.acc()}')\n",
    "\n",
    "    cfg['nn'] = 'gcn'\n",
    "    cfg['path'] = f\"save/finetune/normalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    gcn_cm, gcn = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'gcn: {gcn_cm.acc()}')\n",
    "    \n",
    "    cfg['nn'] = 'transformer'\n",
    "    cfg['path'] = f\"save/finetune/normalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    transformer_cm, transformer = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'transformer: {transformer_cm.acc()}')\n",
    "    \n",
    "    cfg['nn'] = 'dsc_nmp'\n",
    "    cfg['path'] = f\"save/finetune/normalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    dsc_nmp_cm, dsc_nmp = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'dsc_nmp: {dsc_nmp_cm.acc()}')\n",
    "    \n",
    "    cfg['nn'] = 'polymp'\n",
    "    cfg['path'] = f\"save/finetune/normalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    polymp_cm, polymp = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'polymp: {polymp_cm.acc()}')\n",
    "    \n",
    "    cfg['nn'] = 'dsc_polymp'\n",
    "    cfg['path'] = f\"save/finetune/normalised/{cfg['nn']}\"\n",
    "    model = build_model(cfg=cfg)\n",
    "    trainer = Trainer(cfg=cfg) \n",
    "    dsc_polymp_cm, dsc_polymp = trainer.predict(model, dataloader=test_loader, ckpt='epoch100')\n",
    "    print(f'dsc_polymp: {dsc_polymp_cm.acc()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>trans</th>\n",
       "      <th>geom</th>\n",
       "      <th>pos</th>\n",
       "      <th>contour</th>\n",
       "      <th>ggd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>o</td>\n",
       "      <td>POLYGON ((84468.51685698534 53544.362649291375...</td>\n",
       "      <td>[[84468.51685698534, 84457.97171146996, 84458....</td>\n",
       "      <td>[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4,...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 4.0, 3.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O</td>\n",
       "      <td>o</td>\n",
       "      <td>POLYGON ((98690.07408644774 28427.330885788815...</td>\n",
       "      <td>[[98690.07408644774, 98662.90398948287, 98663....</td>\n",
       "      <td>[[0, 1, 2, 3, 0, 1, 2, 3], [1, 2, 3, 0, 3, 0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T</td>\n",
       "      <td>o</td>\n",
       "      <td>POLYGON ((106600.4465117529 41903.3488260107, ...</td>\n",
       "      <td>[[106600.4465117529, 106601.98905117527, 10660...</td>\n",
       "      <td>[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L</td>\n",
       "      <td>o</td>\n",
       "      <td>POLYGON ((46115.13744684386 29701.831047249918...</td>\n",
       "      <td>[[46115.13744684386, 46114.04394946016, 46120....</td>\n",
       "      <td>[[0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6,...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>o</td>\n",
       "      <td>POLYGON ((53772.8657782379 59909.29689727539, ...</td>\n",
       "      <td>[[53772.8657782379, 53771.766852662, 53784.265...</td>\n",
       "      <td>[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 6.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>Y</td>\n",
       "      <td>o</td>\n",
       "      <td>POLYGON ((72725.3557422368 58527.42195344198, ...</td>\n",
       "      <td>[[72725.3557422368, 72744.16937031152, 72746.5...</td>\n",
       "      <td>[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 0, 1, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 5.0, 4.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>Z</td>\n",
       "      <td>o</td>\n",
       "      <td>POLYGON ((107424.52143101924 20821.66476349426...</td>\n",
       "      <td>[[107424.52143101924, 107424.78645064091, 1074...</td>\n",
       "      <td>[[0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6,...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>Y</td>\n",
       "      <td>o</td>\n",
       "      <td>POLYGON ((90446.64688652949 53840.670810161, 9...</td>\n",
       "      <td>[[90446.64688652949, 90450.98456895296, 90464....</td>\n",
       "      <td>[[0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5,...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 4.0, 3.0, 2.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>H</td>\n",
       "      <td>o</td>\n",
       "      <td>POLYGON ((102778.80873325378 44646.7138148793,...</td>\n",
       "      <td>[[102778.80873325378, 102780.8304552531, 10278...</td>\n",
       "      <td>[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>Y</td>\n",
       "      <td>o</td>\n",
       "      <td>POLYGON ((68609.35231769213 50773.10469592757,...</td>\n",
       "      <td>[[68609.35231769213, 68586.67093670281, 68586....</td>\n",
       "      <td>[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 0, 1, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 5.0, 4.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2496 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     name trans                                               geom  \\\n",
       "0       F     o  POLYGON ((84468.51685698534 53544.362649291375...   \n",
       "1       O     o  POLYGON ((98690.07408644774 28427.330885788815...   \n",
       "2       T     o  POLYGON ((106600.4465117529 41903.3488260107, ...   \n",
       "3       L     o  POLYGON ((46115.13744684386 29701.831047249918...   \n",
       "4       E     o  POLYGON ((53772.8657782379 59909.29689727539, ...   \n",
       "...   ...   ...                                                ...   \n",
       "2491    Y     o  POLYGON ((72725.3557422368 58527.42195344198, ...   \n",
       "2492    Z     o  POLYGON ((107424.52143101924 20821.66476349426...   \n",
       "2493    Y     o  POLYGON ((90446.64688652949 53840.670810161, 9...   \n",
       "2494    H     o  POLYGON ((102778.80873325378 44646.7138148793,...   \n",
       "2495    Y     o  POLYGON ((68609.35231769213 50773.10469592757,...   \n",
       "\n",
       "                                                    pos  \\\n",
       "0     [[84468.51685698534, 84457.97171146996, 84458....   \n",
       "1     [[98690.07408644774, 98662.90398948287, 98663....   \n",
       "2     [[106600.4465117529, 106601.98905117527, 10660...   \n",
       "3     [[46115.13744684386, 46114.04394946016, 46120....   \n",
       "4     [[53772.8657782379, 53771.766852662, 53784.265...   \n",
       "...                                                 ...   \n",
       "2491  [[72725.3557422368, 72744.16937031152, 72746.5...   \n",
       "2492  [[107424.52143101924, 107424.78645064091, 1074...   \n",
       "2493  [[90446.64688652949, 90450.98456895296, 90464....   \n",
       "2494  [[102778.80873325378, 102780.8304552531, 10278...   \n",
       "2495  [[68609.35231769213, 68586.67093670281, 68586....   \n",
       "\n",
       "                                                contour  \\\n",
       "0     [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4,...   \n",
       "1     [[0, 1, 2, 3, 0, 1, 2, 3], [1, 2, 3, 0, 3, 0, ...   \n",
       "2     [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13...   \n",
       "3     [[0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6,...   \n",
       "4     [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13...   \n",
       "...                                                 ...   \n",
       "2491  [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 0, 1, ...   \n",
       "2492  [[0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6,...   \n",
       "2493  [[0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5,...   \n",
       "2494  [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13...   \n",
       "2495  [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 0, 1, ...   \n",
       "\n",
       "                                                    ggd  \n",
       "0     [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 4.0, 3.0, 2.0, ...  \n",
       "1     [0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, ...  \n",
       "2     [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...  \n",
       "3     [0.0, 1.0, 2.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, ...  \n",
       "4     [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 6.0, ...  \n",
       "...                                                 ...  \n",
       "2491  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 5.0, 4.0, ...  \n",
       "2492  [0.0, 1.0, 2.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, ...  \n",
       "2493  [0.0, 1.0, 2.0, 3.0, 4.0, 4.0, 3.0, 2.0, 1.0, ...  \n",
       "2494  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...  \n",
       "2495  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 5.0, 4.0, ...  \n",
       "\n",
       "[2496 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_pickle(cfg['osm_test'])\n",
    "test_df = test_df[(test_df.name.isin(cls)) & (test_df.trans=='o')].reset_index(drop=True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = PolygonDataset(test_df, cfg['cls'])\n",
    "test_loader = DataLoader(test_set, batch_size=1, num_workers=cfg['worker'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg['nn'] = 'mpn'\n",
    "cfg['path'] = f\"save/finetune/normalised/{cfg['nn']}/ckpt/epoch100\"\n",
    "\n",
    "mpn = build_model(cfg=cfg)\n",
    "mpn.load_state_dict(torch.load(cfg['path'])['params'])\n",
    "mpn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for data in test_loader:\n",
    "    mpn_pred = mpn(data).argmax(1).item()\n",
    "    pred = cls[mpn_pred]\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoms = gpd.GeoSeries.from_wkt(test_df['geom'].tolist())\n",
    "test_gdf = gpd.GeoDataFrame({'pred': preds, 'geometry': geoms}, crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gdf.to_file('osm_test_preds.gpkg', driver='GPKG', layer='name') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
